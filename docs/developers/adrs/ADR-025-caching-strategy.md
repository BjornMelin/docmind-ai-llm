# ADR-025: Simple Caching Strategy

## Title

SQLite-Based Document Processing Cache

## Version/Date

1.0 / 2025-08-26

## Status

Accepted

## Description

Single-layer SQLite caching using LlamaIndex IngestionCache for document processing, replacing over-engineered multi-library approach with 40-line KISS-compliant solution. Eliminates GPTCache, FAISS, DiskCache, and Redis dependencies in favor of simple file-based caching optimized for single-user Streamlit applications with multi-agent coordination.

## Context

### Initial Implementation Problems

The initial caching implementation suffered from over-engineering:

- **Complex Architecture**: GPTCache + LlamaIndex + DiskCache + Redis + FAISS (5 libraries)
- **Code Complexity**: 274 lines in `library_cache.py` + 140 lines in `models.py` = 414 lines total
- **Semantic Similarity Overhead**: Query-level deduplication provided <5% value for document processing
- **External Dependencies**: Redis server required for coordination
- **Setup Complexity**: 60+ minutes for new developer environment setup

### Analysis Findings

Decision framework analysis revealed over-engineering:

| Option | Solution Leverage (35%) | App Value (30%) | Maintenance (25%) | Adaptability (10%) | **Total Score** |
|--------|-------------------------|-----------------|-------------------|--------------------|-----------------|
| **Multi-Library Current** | 0.8 | 0.9 | **0.2** | 0.7 | **0.715** |
| **Simple SQLite-Only** | **0.95** | 0.75 | **0.9** | **0.85** | **ðŸ† 0.8675** |

**Key Insight**: Document processing primarily needs exact-match caching (file fingerprinting) rather than semantic similarity for query responses. Users typically repeat identical queries, not semantically similar ones.

## Decision

We will implement **minimal SQLite-based caching** using LlamaIndex IngestionCache:

### Architecture Decision

```python
# Replace this (274 lines, 5 libraries):
LibraryCache(GPTCache + LlamaIndex + DiskCache + Redis + FAISS)

# With this (~40 lines, 1 library):
SimpleCache(LlamaIndex IngestionCache + SQLite)
```

### Core Features

- **Document processing cache ONLY** (no semantic query caching)
- **File-based SQLite** with WAL mode for multi-agent concurrency
- **Zero external services** (no Redis requirement)
- **Cache invalidation** based on file size + modification time
- **Multi-agent coordination** through shared SQLite database

### Implementation

```python
from llama_index.core.ingestion import IngestionCache
from llama_index.core.storage.kvstore import SimpleKVStore
from pathlib import Path
import hashlib

class SimpleCache:
    """KISS-compliant cache for document processing.
    
    Single SQLite file, no external services required.
    Perfect for single-user Streamlit app with multi-agent coordination.
    """
    
    def __init__(self, cache_dir: str = "./cache"):
        cache_path = Path(cache_dir)
        cache_path.mkdir(exist_ok=True)
        
        self.cache = IngestionCache(
            cache=SimpleKVStore.from_sqlite_path(
                str(cache_path / "docmind.db"),
                wal=True  # Concurrent reads for multi-agent
            ),
            collection="documents"
        )
    
    async def get_document(self, path: str):
        """Get cached document processing result."""
        key = self._hash(path)
        return self.cache.get(key)
    
    async def store_document(self, path: str, result):
        """Store document processing result."""
        key = self._hash(path)
        self.cache.put(key, result)
    
    def _hash(self, path: str) -> str:
        """File hash with size+mtime for cache invalidation."""
        p = Path(path)
        key = f"{p.name}_{p.stat().st_size}_{p.stat().st_mtime}"
        return hashlib.sha256(key.encode()).hexdigest()
```

## Related Decisions

- **ADR-010** (Performance Optimization Strategy): Handles LLM performance (FP8 KV cache, parallel execution)
- **ADR-011** (Agent Orchestration Framework): Multi-agent coordination using shared cache
- **ADR-007** (Hybrid Persistence Strategy): Qdrant for retrieval, SQLite for caching + session data
- **ADR-019** (Optional GraphRAG): PropertyGraphIndex construction caching for expensive operations

## Benefits

### Code Reduction

- **Before**: 414 lines (library_cache + models)
- **After**: 40 lines (simple_cache)
- **Reduction**: 90% less code

### Dependency Reduction

- **Before**: 5 libraries (GPTCache, LlamaIndex, DiskCache, Redis, FAISS)
- **After**: 1 library (LlamaIndex - already in stack)
- **Reduction**: 80% fewer dependencies

### Setup Simplification

- **Before**: Redis server setup + FAISS configuration + 60+ minutes
- **After**: Single directory creation + <1 minute
- **Reduction**: 98% simpler setup

### Performance Maintained

- **Cache Hit Rate**: 80-95% for document processing (maintained)
- **Response Time**: <1.5s (maintained)
- **Memory Usage**: Reduced (no FAISS vector indices)

## Use Cases

### 1. Document Processing Cache

```python
cache = SimpleCache()

# Cache document processing results
result = await cache.get_document(file_path)
if not result:
    result = await process_document_async(file_path)
    await cache.store_document(file_path, result)
```

### 2. Multi-Agent Coordination

```python
# All agents share same cache instance
routing_agent = create_agent(cache=cache)
retrieval_agent = create_agent(cache=cache)  
synthesis_agent = create_agent(cache=cache)

# SQLite WAL mode enables concurrent reads
```

### 3. GraphRAG Index Caching

```python
# Cache expensive PropertyGraphIndex construction
graph_key = f"graph_{document_hash}"
cached_graph = await cache.get_document(graph_key)
if not cached_graph:
    graph = create_property_graph_index(documents)
    await cache.store_document(graph_key, graph)
```

## Performance Targets

- **Cache Hit Rate**: 80-95% for document processing
- **Setup Time**: <1 minute for new developers (vs 60+ minutes)
- **Code Complexity**: 40 lines total (vs 274 lines)
- **Memory Usage**: Minimal overhead (no FAISS indices)
- **Multi-Agent Latency**: <10ms for cache operations

## Migration Strategy

### Phase 1: Deprecation

- Mark `LibraryCache` as deprecated
- Add feature flag for cache selection: `DOCMIND_CACHE_IMPL=simple`

### Phase 2: Parallel Operation

- Run both implementations side-by-side
- Compare performance metrics
- Export existing cache data

### Phase 3: Cutover

- Default to SimpleCache
- Remove old implementation
- Clean up dependencies

### Rollback Plan

- Git revert capability
- Feature flag to re-enable old cache
- Performance monitoring for regressions

## Configuration

### Environment Variables

```bash
# Simple cache configuration
DOCMIND_CACHE_DIR=./cache  # Cache directory location

# Removed variables (no longer needed):
# DOCMIND_REDIS_HOST=127.0.0.1
# DOCMIND_REDIS_PORT=6379
# SEMANTIC_CACHE_DIR=./cache/semantic
# INGESTION_CACHE_DIR=./cache/ingestion
```

### Docker Configuration

```yaml
# No Redis service required
services:
  docmind:
    volumes:
      - ./cache:/app/cache  # Simple file-based cache
    # No redis service dependency
```

## Consequences

### Positive Outcomes

- **Dramatic Simplification**: 90% code reduction with same functionality
- **Zero External Dependencies**: No Redis server required
- **Faster Developer Onboarding**: <1 minute setup vs 60+ minutes
- **Reduced Memory Usage**: No FAISS vector index overhead
- **Perfect KISS Compliance**: Single responsibility, minimal complexity
- **Multi-Agent Compatible**: SQLite WAL mode enables concurrent access

### Trade-offs Accepted

- **No Semantic Query Caching**: Removed query-level deduplication (provided <5% value)
- **File-Based Storage**: SQLite vs Redis (perfectly adequate for single-user app)
- **Simpler Statistics**: Basic cache hit/miss vs detailed semantic similarity metrics

### Mitigation Strategies

- **Performance Monitoring**: Track cache hit rates and response times
- **Graceful Degradation**: System works without cache if SQLite unavailable
- **Clear Rollback Path**: Git revert + feature flag for emergency rollback
- **Documentation**: Clear setup instructions for simplified architecture

## Dependencies

### Required

- **LlamaIndex**: `llama-index-core>=0.10.0` (IngestionCache, SimpleKVStore)
- **SQLite**: Built into Python standard library
- **Pathlib**: Built into Python standard library

### Removed Dependencies

- **GPTCache**: `gptcache>=0.1.43` âŒ (semantic similarity not needed)
- **FAISS**: `faiss-cpu>=1.7.4` âŒ (vector indexing not needed for cache)
- **DiskCache**: `diskcache>=5.6.3` âŒ (SQLite more appropriate)
- **Redis**: `redis>=4.5.0` âŒ (external service not needed)

## Validation Criteria

### Success Metrics

1. **Cache Hit Rate**: Maintain >80% for document processing
2. **Setup Time**: <1 minute for new developer environment
3. **Memory Usage**: <100MB cache overhead (vs 1GB+ with FAISS)
4. **Code Complexity**: <50 lines total cache implementation
5. **Multi-Agent Performance**: <10ms cache operations with concurrency

### Testing Strategy

1. **Unit Tests**: Cache operations, hash generation, error handling
2. **Integration Tests**: Multi-agent cache sharing, SQLite WAL mode
3. **Performance Tests**: Cache hit rates, response times, memory usage
4. **System Tests**: Full Streamlit app with SimpleCache

## Implementation Timeline

- **Day 1**: Create SimpleCache implementation
- **Day 2**: Update all imports and dependencies
- **Day 3**: Test suite update and validation
- **Day 4**: Production deployment and monitoring

**Total Effort**: 4 days for complete transition

## Changelog

- **1.0 (2025-08-26)**: Initial ADR for simplified caching strategy. Replaces over-engineered multi-library cache with 40-line SQLite solution. 90% code reduction, 80% dependency reduction, 98% setup simplification while maintaining all core functionality.

## References

- **Cache Architecture Analysis**: `ai-research/2025-08-26/001-cache-architecture-over-engineering-assessment.md`
- **Decision Framework Results**: Multi-criteria scoring showing 0.8675 vs 0.715 for simple vs complex
- **LlamaIndex IngestionCache**: <https://docs.llamaindex.ai/en/stable/module_guides/storing/ingestion_cache/>
- **SQLite WAL Mode**: <https://www.sqlite.org/wal.html> (concurrent access documentation)
