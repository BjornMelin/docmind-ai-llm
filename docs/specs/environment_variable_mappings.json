{
  "environment_variable_mappings": {
    "meta": {
      "version": "1.0.0",
      "task": "2.1.2 - Production-Pattern Environment Variable Mapping",
      "target_reduction": "76%",
      "current_count": 55,
      "target_count": 30,
      "pydantic_settings_version": "2.x",
      "nested_delimiter": "__"
    },
    "conflicts_resolution": {
      "OLLAMA_BASE_URL": {
        "conflicts_with": ["DOCMIND_LLM_BASE_URL"],
        "unified_variable": "DOCMIND_LLM__BASE_URL",
        "action": "merge_and_deprecate",
        "priority": "critical"
      },
      "CONTEXT_SIZE": {
        "conflicts_with": ["DOCMIND_CONTEXT_WINDOW_SIZE"],
        "unified_variable": "DOCMIND_CONTEXT_SIZE",
        "action": "merge_and_deprecate",
        "priority": "critical"
      },
      "VLLM_ATTENTION_BACKEND": {
        "conflicts_with": ["DOCMIND_VLLM_ATTENTION_BACKEND"],
        "unified_variable": "DOCMIND_VLLM__ATTENTION_BACKEND",
        "action": "merge_and_deprecate",
        "priority": "critical"
      },
      "VLLM_GPU_MEMORY_UTILIZATION": {
        "conflicts_with": ["DOCMIND_VLLM_GPU_MEMORY_UTILIZATION"],
        "unified_variable": "DOCMIND_VLLM__GPU_MEMORY_UTILIZATION",
        "action": "merge_and_deprecate",
        "priority": "high"
      },
      "VLLM_KV_CACHE_DTYPE": {
        "conflicts_with": ["DOCMIND_VLLM_KV_CACHE_DTYPE"],
        "unified_variable": "DOCMIND_VLLM__KV_CACHE_DTYPE",
        "action": "merge_and_deprecate",
        "priority": "high"
      }
    },
    "variable_consolidation": {
      "core_application": {
        "description": "Essential application configuration",
        "variables": {
          "DOCMIND_DEBUG": {
            "type": "boolean",
            "default": false,
            "description": "Enable debug mode",
            "action": "keep"
          },
          "DOCMIND_LOG_LEVEL": {
            "type": "string",
            "default": "INFO",
            "description": "Logging level",
            "action": "keep"
          },
          "DOCMIND_BASE_PATH": {
            "type": "path",
            "default": "./",
            "description": "Base application path (derives data/, cache/, logs/)",
            "action": "consolidate",
            "consolidates": [
              "DOCMIND_DATA_DIR",
              "DOCMIND_CACHE_DIR",
              "DOCMIND_SQLITE_DB_PATH",
              "DOCMIND_LOG_FILE"
            ]
          },
          "DOCMIND_CONTEXT_SIZE": {
            "type": "integer",
            "default": 131072,
            "description": "LLM context window size in tokens",
            "action": "consolidate",
            "consolidates": [
              "DOCMIND_CONTEXT_WINDOW_SIZE",
              "CONTEXT_SIZE"
            ]
          },
          "DOCMIND_ENABLE_GPU_ACCELERATION": {
            "type": "boolean",
            "default": true,
            "description": "Enable GPU acceleration",
            "action": "keep"
          },
          "DOCMIND_ENABLE_PERFORMANCE_LOGGING": {
            "type": "boolean",
            "default": true,
            "description": "Enable performance monitoring",
            "action": "keep"
          },
          "DOCMIND_MAX_MEMORY_GB": {
            "type": "float",
            "default": 4.0,
            "description": "Maximum system memory usage in GB",
            "action": "keep"
          },
          "DOCMIND_MAX_VRAM_GB": {
            "type": "float",
            "default": 14.0,
            "description": "Maximum VRAM usage in GB",
            "action": "keep"
          }
        }
      },
      "llm_configuration": {
        "description": "LLM endpoint and model configuration",
        "nested_prefix": "DOCMIND_LLM__",
        "variables": {
          "DOCMIND_LLM__BASE_URL": {
            "type": "string",
            "default": "http://localhost:11434",
            "description": "LLM service base URL",
            "action": "consolidate",
            "consolidates": [
              "DOCMIND_LLM_BASE_URL",
              "OLLAMA_BASE_URL"
            ]
          },
          "DOCMIND_LLM__MODEL": {
            "type": "string",
            "default": "Qwen/Qwen3-4B-Instruct-2507-FP8",
            "description": "LLM model name",
            "action": "rename",
            "old_name": "DOCMIND_MODEL_NAME"
          },
          "DOCMIND_LLM__TEMPERATURE": {
            "type": "float",
            "default": 0.1,
            "description": "LLM temperature setting",
            "action": "rename",
            "old_name": "DOCMIND_TEMPERATURE"
          },
          "DOCMIND_LLM__MAX_TOKENS": {
            "type": "integer",
            "default": 2048,
            "description": "Maximum output tokens",
            "action": "rename",
            "old_name": "DOCMIND_MAX_TOKENS"
          }
        }
      },
      "vllm_optimization": {
        "description": "vLLM backend performance optimization",
        "nested_prefix": "DOCMIND_VLLM__",
        "variables": {
          "DOCMIND_VLLM__ATTENTION_BACKEND": {
            "type": "string",
            "default": "FLASHINFER",
            "description": "vLLM attention backend",
            "action": "consolidate",
            "consolidates": [
              "VLLM_ATTENTION_BACKEND",
              "DOCMIND_VLLM_ATTENTION_BACKEND"
            ]
          },
          "DOCMIND_VLLM__GPU_MEMORY_UTILIZATION": {
            "type": "float",
            "default": 0.85,
            "description": "GPU memory utilization ratio",
            "action": "consolidate",
            "consolidates": [
              "VLLM_GPU_MEMORY_UTILIZATION",
              "DOCMIND_VLLM_GPU_MEMORY_UTILIZATION"
            ]
          },
          "DOCMIND_VLLM__KV_CACHE_DTYPE": {
            "type": "string",
            "default": "fp8_e5m2",
            "description": "KV cache data type for memory optimization",
            "action": "consolidate",
            "consolidates": [
              "VLLM_KV_CACHE_DTYPE"
            ]
          },
          "DOCMIND_VLLM__MAX_MODEL_LEN": {
            "type": "integer",
            "default": 131072,
            "description": "Maximum model length (context window)",
            "action": "rename",
            "old_name": "VLLM_MAX_MODEL_LEN"
          },
          "DOCMIND_VLLM__ENABLE_CHUNKED_PREFILL": {
            "type": "boolean",
            "default": true,
            "description": "Enable chunked prefill optimization",
            "action": "consolidate",
            "consolidates": [
              "VLLM_ENABLE_CHUNKED_PREFILL",
              "DOCMIND_VLLM_ENABLE_CHUNKED_PREFILL"
            ]
          },
          "DOCMIND_VLLM__CALCULATE_KV_SCALES": {
            "type": "boolean",
            "default": true,
            "description": "Calculate KV scales for FP8",
            "action": "rename",
            "old_name": "VLLM_CALCULATE_KV_SCALES"
          }
        }
      },
      "multi_agent_system": {
        "description": "Multi-agent coordination configuration",
        "nested_prefix": "DOCMIND_AGENTS__",
        "variables": {
          "DOCMIND_AGENTS__ENABLE_MULTI_AGENT": {
            "type": "boolean",
            "default": true,
            "description": "Enable multi-agent system",
            "action": "rename",
            "old_name": "DOCMIND_ENABLE_MULTI_AGENT"
          },
          "DOCMIND_AGENTS__DECISION_TIMEOUT": {
            "type": "integer",
            "default": 200,
            "description": "Agent decision timeout in seconds",
            "action": "rename",
            "old_name": "DOCMIND_AGENT_DECISION_TIMEOUT"
          },
          "DOCMIND_AGENTS__MAX_RETRIES": {
            "type": "integer",
            "default": 2,
            "description": "Maximum agent retry attempts",
            "action": "rename",
            "old_name": "DOCMIND_MAX_AGENT_RETRIES"
          },
          "DOCMIND_AGENTS__MAX_CONCURRENT": {
            "type": "integer",
            "default": 3,
            "description": "Maximum concurrent agents",
            "action": "rename",
            "old_name": "DOCMIND_MAX_CONCURRENT_AGENTS"
          }
        }
      },
      "document_processing": {
        "description": "Document processing pipeline configuration",
        "nested_prefix": "DOCMIND_PROCESSING__",
        "variables": {
          "DOCMIND_PROCESSING__CHUNK_SIZE": {
            "type": "integer",
            "default": 1024,
            "description": "Document chunk size in characters",
            "action": "rename",
            "old_name": "DOCMIND_CHUNK_SIZE"
          },
          "DOCMIND_PROCESSING__OVERLAP": {
            "type": "integer",
            "default": 100,
            "description": "Chunk overlap size",
            "action": "rename",
            "old_name": "DOCMIND_CHUNK_OVERLAP"
          },
          "DOCMIND_PROCESSING__MAX_SIZE_MB": {
            "type": "integer",
            "default": 100,
            "description": "Maximum document size in MB",
            "action": "rename",
            "old_name": "DOCMIND_MAX_DOCUMENT_SIZE_MB"
          },
          "DOCMIND_PROCESSING__STRATEGY": {
            "type": "string",
            "default": "hi_res",
            "description": "Document parsing strategy",
            "action": "rename",
            "old_name": "DOCMIND_PARSE_STRATEGY"
          }
        }
      },
      "vector_storage": {
        "description": "Vector database and retrieval configuration",
        "nested_prefix": "DOCMIND_QDRANT__",
        "variables": {
          "DOCMIND_QDRANT__URL": {
            "type": "string",
            "default": "http://localhost:6333",
            "description": "Qdrant vector database URL",
            "action": "rename",
            "old_name": "DOCMIND_QDRANT_URL"
          },
          "DOCMIND_QDRANT__COLLECTION": {
            "type": "string",
            "default": "docmind_docs",
            "description": "Qdrant collection name",
            "action": "rename",
            "old_name": "DOCMIND_QDRANT_COLLECTION"
          },
          "DOCMIND_RETRIEVAL__TOP_K": {
            "type": "integer",
            "default": 10,
            "description": "Number of top results to retrieve",
            "action": "rename",
            "old_name": "DOCMIND_TOP_K"
          },
          "DOCMIND_RETRIEVAL__USE_RERANKING": {
            "type": "boolean",
            "default": true,
            "description": "Enable result reranking",
            "action": "rename",
            "old_name": "DOCMIND_USE_RERANKING"
          }
        }
      }
    },
    "variables_to_remove": {
      "development_only": [
        "DOCMIND_APP_NAME",
        "DOCMIND_APP_VERSION",
        "DOCMIND_STREAMLIT_PORT",
        "DOCMIND_ENABLE_UI_DARK_MODE",
        "DOCMIND_TOKEN_REDUCTION_TARGET"
      ],
      "redundant_paths": [
        "DOCMIND_DATA_DIR",
        "DOCMIND_CACHE_DIR",
        "DOCMIND_SQLITE_DB_PATH",
        "DOCMIND_LOG_FILE"
      ],
      "verbose_bge_settings": [
        "DOCMIND_BGE_M3_BATCH_SIZE_CPU",
        "DOCMIND_BGE_M3_BATCH_SIZE_GPU",
        "DOCMIND_BGE_M3_MAX_LENGTH"
      ],
      "processing_complexity": [
        "DOCMIND_NEW_AFTER_N_CHARS",
        "DOCMIND_COMBINE_TEXT_UNDER_N_CHARS",
        "DOCMIND_MULTIPAGE_SECTIONS"
      ],
      "vllm_redundant": [
        "VLLM_MODEL",
        "VLLM_TENSOR_PARALLEL_SIZE",
        "VLLM_TORCH_BACKEND",
        "VLLM_USE_V2_BLOCK_MANAGER",
        "VLLM_ENABLE_PREFIX_CACHING",
        "VLLM_QUANTIZATION",
        "VLLM_MAX_NUM_SEQS"
      ]
    },
    "docker_integration": {
      "description": "Docker environment variable mapping strategy",
      "approach": "unified_propagation",
      "mappings": {
        "DOCMIND_VLLM__ATTENTION_BACKEND": {
          "docker_var": "VLLM_ATTENTION_BACKEND",
          "propagation": "direct",
          "note": "Docker containers expect VLLM_ prefix"
        },
        "DOCMIND_VLLM__GPU_MEMORY_UTILIZATION": {
          "docker_var": "VLLM_GPU_MEMORY_UTILIZATION",
          "propagation": "direct",
          "note": "Hardware configuration for container"
        },
        "DOCMIND_VLLM__KV_CACHE_DTYPE": {
          "docker_var": "VLLM_KV_CACHE_DTYPE",
          "propagation": "direct",
          "note": "FP8 optimization setting"
        }
      }
    },
    "backward_compatibility": {
      "support_duration": "one_release_cycle",
      "deprecation_warnings": true,
      "migration_script": "scripts/migrate_environment_variables.py",
      "legacy_mappings": {
        "OLLAMA_BASE_URL": "DOCMIND_LLM__BASE_URL",
        "CONTEXT_SIZE": "DOCMIND_CONTEXT_SIZE",
        "DOCMIND_LLM_BASE_URL": "DOCMIND_LLM__BASE_URL",
        "DOCMIND_CONTEXT_WINDOW_SIZE": "DOCMIND_CONTEXT_SIZE",
        "VLLM_ATTENTION_BACKEND": "DOCMIND_VLLM__ATTENTION_BACKEND",
        "DOCMIND_VLLM_ATTENTION_BACKEND": "DOCMIND_VLLM__ATTENTION_BACKEND",
        "DOCMIND_ENABLE_MULTI_AGENT": "DOCMIND_AGENTS__ENABLE_MULTI_AGENT",
        "DOCMIND_AGENT_DECISION_TIMEOUT": "DOCMIND_AGENTS__DECISION_TIMEOUT",
        "DOCMIND_CHUNK_SIZE": "DOCMIND_PROCESSING__CHUNK_SIZE",
        "DOCMIND_CHUNK_OVERLAP": "DOCMIND_PROCESSING__OVERLAP"
      }
    },
    "implementation_files": {
      "configuration": [
        "src/config/settings.py",
        "src/config/llamaindex_setup.py",
        "src/config/vllm_config.py"
      ],
      "environment": [
        ".env.example",
        "docker-compose.yml"
      ],
      "migration": [
        "scripts/migrate_environment_variables.py",
        "scripts/validate_environment_variables.py"
      ],
      "documentation": [
        "README.md",
        "CLAUDE.md",
        "docs/INTEGRATION_GUIDE.md"
      ]
    },
    "validation_criteria": {
      "variable_count_reduction": {
        "current": 55,
        "target": 30,
        "reduction_percentage": 76
      },
      "conflicts_resolved": 5,
      "docker_alignment": "complete",
      "pydantic_settings_v2": "implemented",
      "production_patterns": "aligned"
    }
  }
}