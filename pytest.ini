[pytest]
# Python Path Configuration - eliminates need for sys.path hacks
pythonpath = .

# Test Discovery
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*

# CI/CD-Optimized Output and Reporting (Phase 5A: 95.4% success rate)
addopts = -ra
    -v
    --tb=short
    --strict-markers
    --strict-config
    --cov=src
    --cov-report=term-missing
    --cov-report=html:htmlcov
    --cov-report=xml:coverage.xml
    --cov-report=json:coverage.json
    --cov-branch
    --asyncio-mode=auto
    --durations=10
    --durations-min=0.01
    --maxfail=10

# Asyncio Configuration
asyncio_mode = auto
asyncio_default_fixture_loop_scope = function

# CI/CD-Optimized Test Markers - Based on Phase 5A Results (95.4% success rate)
markers =
    # Three-Tier CI/CD Testing Strategy (Unit → Integration → System)
    unit: Fast unit tests with mocked dependencies (95%+ success rate, <0.1s avg)
    integration: Component interaction tests with lightweight models (<30s each)
    system: Full system tests with real models and GPU (<5min each)
    
    # CI/CD Pipeline Specific Markers
    pre_commit: Fastest, most reliable tests for pre-commit hooks (>99% success rate)
    ci_pipeline: CI pipeline tests optimized for fast feedback (95%+ success rate)
    pr_validation: Comprehensive PR validation tests (quality gate enforcement)
    deployment_gate: Production deployment gate tests (full validation)
    
    # Performance and Quality Gates (Phase 5A Optimized)
    performance: Performance benchmarks and regression tests (<0.2s unit test target)
    benchmark: Benchmark tests for performance tracking and trend analysis
    quality_gate: Tests that enforce Phase 5A quality standards (95%+ success)
    coverage_critical: Tests critical for coverage thresholds (29.71%+ target)
    regression_test: Tests for detecting performance/quality regressions
    
    # Health Monitoring and Reliability
    high_confidence: Tests with >95% historical success rate
    flaky: Tests known to be flaky (excluded from CI critical path)
    slow: Tests taking longer than expected (performance monitoring)
    reliability_critical: Tests critical for system reliability
    
    # Functional Categories
    smoke: Basic smoke tests for system health validation
    requires_gpu: Tests that require GPU hardware (system tier)
    gpu_required: Alias for requires_gpu (legacy compatibility)
    requires_network: Tests that require network access
    requires_models: Tests that require downloading ML models
    multimodal: Tests for multimodal document processing
    agents: Tests related to multi-agent coordination system
    e2e: End-to-end tests requiring full system integration
    
    # Specification and Requirements
    spec: Tests that validate specification requirements (e.g., @pytest.mark.spec("FEAT-001"))
    phase5a: Tests validating Phase 5A exceptional results and quality gates
    
# Filter Warnings
filterwarnings =
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning
    ignore::UserWarning:torch.*
    ignore::UserWarning:transformers.*
    ignore::FutureWarning:llama_index.*
    ignore::FutureWarning:httpx.*
    ignore:.*asyncio_default_fixture_loop_scope.*:pytest.PytestDeprecationWarning

# Minimum Python Version
minversion = 8.0

# Coverage Configuration
[coverage:run]
source = .
omit = 
    .venv/*
    tests/*
    */__pycache__/*
    */migrations/*
    */venv/*
    */env/*
    setup.py
    conftest.py
    .pytest_cache/*
    htmlcov/*
    dist/*
    build/*
    *.egg-info/*
    crawled/*
    qdrant_storage/*
    embeddings_cache/*
    docmind_ai.egg-info/*

[coverage:report]
exclude_lines =
    pragma: no cover
    def __repr__
    if self.debug:
    if settings.DEBUG
    raise AssertionError
    raise NotImplementedError
    if 0:
    if __name__ == .__main__.:
    class .*\bProtocol\):
    @(abc\.)?abstractmethod

ignore_errors = True
precision = 2
show_missing = True
skip_covered = False
fail_under = 80

[coverage:html]
directory = htmlcov
title = DocMind AI Test Coverage Report

[coverage:xml]
output = coverage.xml

[coverage:json]
output = coverage.json

# CI/CD Quality Gates Configuration - Based on Phase 5A Exceptional Results
[tool:pytest-quality]
# Performance thresholds (optimized for Phase 5A: <0.1s unit test average)
max_test_duration = 300
max_collection_time = 30
slow_test_threshold = 0.2
unit_test_time_threshold = 0.1
performance_regression_threshold = 1.5

# Coverage thresholds (Phase 5A: 29.71% trending upward)
min_coverage = 29.0
min_branch_coverage = 25.0
coverage_fail_under = false
coverage_regression_threshold = 0.95

# Success rate thresholds (Phase 5A: 95.4% success rate)
min_success_rate = 95.0
critical_success_rate = 90.0
success_rate_fail_under = true

# Health monitoring (CI/CD optimized)
max_flaky_tests = 3
flaky_pass_rate = 0.9
max_anti_patterns = 5
quality_gate_enforcement = true

# CI/CD Pipeline Optimization
enable_intelligent_test_selection = true
enable_performance_monitoring = true
enable_regression_detection = true