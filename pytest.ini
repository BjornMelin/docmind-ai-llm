[pytest]
# Python Path Configuration - eliminates need for sys.path hacks
pythonpath = .

# Test Discovery
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*

# Output and Reporting
addopts = -ra
    -v
    --tb=short
    --strict-markers
    --strict-config
    --cov=.
    --cov-report=term-missing
    --cov-report=html:htmlcov
    --cov-report=xml:coverage.xml
    --cov-report=json:coverage.json
    --cov-branch
    --asyncio-mode=auto

# Asyncio Configuration
asyncio_mode = auto
asyncio_default_fixture_loop_scope = function

# Custom Test Markers - Three-Tier Testing Strategy with Quality Gates
markers =
    # Three-Tier Testing Strategy (Unit → Integration → System)
    unit: Fast unit tests with mocked dependencies (<5s each)
    integration: Component interaction tests with lightweight models (<30s each)
    system: Full system tests with real models and GPU (<5min each)
    
    # Performance and Quality Gates
    performance: Performance benchmarks and regression tests
    benchmark: Benchmark tests for performance tracking
    flaky: Tests known to be flaky (for health monitoring)
    slow: Tests taking longer than expected (health monitoring)
    quality_gate: Tests that enforce quality standards
    coverage_critical: Tests critical for coverage thresholds
    
    # Legacy markers (maintained for backward compatibility)
    requires_gpu: marks tests that require GPU hardware
    gpu_required: alias for requires_gpu
    requires_network: marks tests that require network access
    requires_models: marks tests that require downloading ML models
    smoke: marks tests as smoke tests for basic functionality
    gpu: marks tests that require GPU functionality
    multimodal: marks tests for multimodal document processing
    spec: marks tests that validate specification requirements (e.g., @pytest.mark.spec("FEAT-001"))
    agents: marks tests related to multi-agent coordination system
    e2e: marks tests as end-to-end tests requiring full system integration
    
# Filter Warnings
filterwarnings =
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning
    ignore::UserWarning:torch.*
    ignore::UserWarning:transformers.*
    ignore::FutureWarning:llama_index.*
    ignore::FutureWarning:httpx.*
    ignore:.*asyncio_default_fixture_loop_scope.*:pytest.PytestDeprecationWarning

# Minimum Python Version
minversion = 8.0

# Coverage Configuration
[coverage:run]
source = .
omit = 
    .venv/*
    tests/*
    */__pycache__/*
    */migrations/*
    */venv/*
    */env/*
    setup.py
    conftest.py
    .pytest_cache/*
    htmlcov/*
    dist/*
    build/*
    *.egg-info/*
    crawled/*
    qdrant_storage/*
    embeddings_cache/*
    docmind_ai.egg-info/*

[coverage:report]
exclude_lines =
    pragma: no cover
    def __repr__
    if self.debug:
    if settings.DEBUG
    raise AssertionError
    raise NotImplementedError
    if 0:
    if __name__ == .__main__.:
    class .*\bProtocol\):
    @(abc\.)?abstractmethod

ignore_errors = True
precision = 2
show_missing = True
skip_covered = False
fail_under = 80

[coverage:html]
directory = htmlcov
title = DocMind AI Test Coverage Report

[coverage:xml]
output = coverage.xml

[coverage:json]
output = coverage.json

# Quality Gates Configuration
[tool:pytest-quality]
# Performance thresholds
max_test_duration = 300
max_collection_time = 30
slow_test_threshold = 5

# Coverage thresholds  
min_coverage = 80
min_branch_coverage = 75
coverage_fail_under = true

# Health monitoring
max_flaky_tests = 5
flaky_pass_rate = 0.8
max_anti_patterns = 10