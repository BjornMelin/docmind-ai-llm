{
  "atomic_changes": [
    {
      "blockers": [],
      "dependencies": [],
      "description": "Create new configuration module that bridges app settings with LlamaIndex Settings",
      "estimated_effort_hours": 8,
      "files_changed": [
        "src/config/llamaindex_settings.py"
      ],
      "files_created": [
        "src/config/llamaindex_settings.py",
        "src/config/__init__.py"
      ],
      "implementation_details": {
        "configuration_mappings": {
          "Settings.chunk_overlap": "app_settings.chunk_overlap",
          "Settings.chunk_size": "app_settings.chunk_size",
          "Settings.embed_model": "OpenAIEmbedding(model=app_settings.embedding_model)",
          "Settings.llm": "OpenAI(model=app_settings.llm_model)",
          "Settings.transformations": "[SentenceSplitter(chunk_size=..., chunk_overlap=...)]"
        },
        "integration_points": [
          "src.models.core.settings",
          "llama_index.core.Settings",
          "llama_index.llms.openai.OpenAI",
          "llama_index.embeddings.openai.OpenAIEmbedding"
        ],
        "key_functions": [
          "configure_llamaindex_settings()",
          "get_current_settings()",
          "validate_settings_compatibility()"
        ]
      },
      "phase": 1,
      "pr_id": "PR-1.1",
      "priority": "critical",
      "risk_level": "low",
      "rollback_plan": "Delete created files, no dependencies to update",
      "success_criteria": [
        "Settings configuration module created and functional",
        "All LlamaIndex Settings properties correctly mapped",
        "Configuration validation passes",
        "Ruff linting passes without errors"
      ],
      "title": "Create LlamaIndex Settings Configuration Module",
      "verification_commands": [
        "python -c \"from src.config.llamaindex_settings import configure_llamaindex_settings, get_current_settings; configure_llamaindex_settings(); print(get_current_settings())\"",
        "pytest tests/unit/test_config_validation.py -v",
        "ruff check src/config/llamaindex_settings.py",
        "ruff format src/config/llamaindex_settings.py"
      ]
    },
    {
      "blockers": [],
      "dependencies": [
        "PR-1.1"
      ],
      "description": "Integrate LlamaIndex Settings configuration into application initialization",
      "estimated_effort_hours": 6,
      "files_changed": [
        "src/app.py"
      ],
      "files_created": [],
      "implementation_details": {
        "integration_points": [
          "Application main() function",
          "Streamlit app initialization",
          "Component initialization sequence"
        ],
        "startup_sequence": [
          "Import configure_llamaindex_settings",
          "Call configure_llamaindex_settings() early in initialization",
          "Verify Settings propagation to components",
          "Add error handling and logging"
        ]
      },
      "phase": 1,
      "pr_id": "PR-1.2",
      "priority": "critical",
      "risk_level": "medium",
      "rollback_plan": "Remove Settings configuration call, restore previous initialization",
      "success_criteria": [
        "Application starts successfully with Settings integration",
        "Settings propagate to all LlamaIndex components",
        "No regression in application startup time",
        "Integration tests pass"
      ],
      "title": "Integrate Settings Configuration in Application Startup",
      "verification_commands": [
        "python -m src.app --help",
        "python -c \"from src.app import initialize_application; from llama_index.core import Settings; initialize_application(); print(f'LLM: {Settings.llm}'); print(f'Embedding: {Settings.embed_model}')\"",
        "pytest tests/integration/test_pipeline_integration.py -v"
      ]
    },
    {
      "blockers": [],
      "dependencies": [
        "PR-1.1",
        "PR-1.2"
      ],
      "description": "Update agent factory to use configured Settings instead of manual LLM instantiation",
      "estimated_effort_hours": 10,
      "files_changed": [
        "src/agents/agent_factory.py"
      ],
      "files_created": [],
      "implementation_details": {
        "code_changes": {
          "after": "llm = Settings.llm  # Automatically configured",
          "before": "llm = OpenAI(model=app_settings.llm_model)"
        },
        "refactoring_targets": [
          "Remove manual OpenAI() instantiation",
          "Replace with Settings.llm usage",
          "Update tool creation to use Settings.embed_model",
          "Maintain backward compatibility during transition"
        ]
      },
      "phase": 1,
      "pr_id": "PR-1.3",
      "priority": "critical",
      "risk_level": "medium",
      "rollback_plan": "Restore manual LLM instantiation patterns",
      "success_criteria": [
        "Agent factory uses Settings.llm and Settings.embed_model",
        "All agent creation tests pass",
        "Agent functionality preserved",
        "Code complexity reduced"
      ],
      "title": "Migrate Agent Factory to Use LlamaIndex Settings",
      "verification_commands": [
        "pytest tests/unit/test_agent_factory.py -v",
        "python -c \"from src.config.llamaindex_settings import configure_llamaindex_settings; from src.agents.agent_factory import create_react_agent; configure_llamaindex_settings(); agent = create_react_agent([]); print('Agent created successfully with Settings integration')\""
      ]
    },
    {
      "blockers": [],
      "dependencies": [
        "PR-1.1",
        "PR-1.2",
        "PR-1.3"
      ],
      "description": "Finalize Settings migration by updating utilities and cleaning up duplicate configuration",
      "estimated_effort_hours": 12,
      "files_changed": [
        "src/utils/core.py",
        "src/utils/embedding.py",
        "src/utils/document.py",
        "src/models/core.py"
      ],
      "files_created": [],
      "implementation_details": {
        "cleanup_targets": [
          "Remove duplicate configuration fields from Settings class",
          "Update utility functions to use Settings",
          "Maintain backward compatibility for tests",
          "Add deprecation warnings for old patterns"
        ],
        "code_reduction_estimate": "200+ lines eliminated"
      },
      "phase": 1,
      "pr_id": "PR-1.4",
      "priority": "critical",
      "risk_level": "high",
      "rollback_plan": "Restore original Settings class configuration",
      "success_criteria": [
        "All tests pass with no regressions",
        "200+ lines of duplicate configuration eliminated",
        "Ruff linting passes",
        "End-to-end functionality preserved"
      ],
      "title": "Update Remaining Components and Clean Up Custom Settings",
      "verification_commands": [
        "pytest tests/ -v --tb=short",
        "python -m pytest tests/e2e/test_end_to_end.py -v",
        "ruff check src/ --fix"
      ]
    },
    {
      "blockers": [
        "Docker environment availability"
      ],
      "dependencies": [
        "PR-1.1"
      ],
      "description": "Set up Redis infrastructure and implement IngestionCache configuration",
      "estimated_effort_hours": 10,
      "files_changed": [],
      "files_created": [
        "docker-compose.yml",
        "src/config/cache_config.py",
        ".env.example"
      ],
      "implementation_details": {
        "cache_configuration": {
          "backend": "RedisKVStore with fallback to SimpleKVStore",
          "collection": "docmind_transformations",
          "connection": "127.0.0.1:6379",
          "retry_logic": "3 attempts with exponential backoff",
          "timeout": "5 seconds"
        },
        "infrastructure_components": [
          "Redis Alpine container configuration",
          "Volume persistence for Redis data",
          "Network configuration for cache access",
          "Health checks and restart policies"
        ]
      },
      "phase": 2,
      "pr_id": "PR-2.1",
      "priority": "high",
      "risk_level": "medium",
      "rollback_plan": "Stop Redis container, disable cache configuration",
      "success_criteria": [
        "Redis container runs successfully",
        "IngestionCache creates without errors",
        "Fallback to SimpleKVStore works when Redis unavailable",
        "Cache configuration is environment-aware"
      ],
      "title": "Redis Infrastructure and IngestionCache Setup",
      "verification_commands": [
        "docker-compose up -d redis",
        "python -c \"from src.config.cache_config import INGEST_CACHE; print(f'Cache created: {INGEST_CACHE is not None}')\"",
        "docker exec docmind_redis redis-cli ping"
      ]
    },
    {
      "blockers": [],
      "dependencies": [
        "PR-2.1"
      ],
      "description": "Integrate IngestionCache with document processing pipelines",
      "estimated_effort_hours": 14,
      "files_changed": [
        "src/utils/document.py",
        "src/utils/embedding.py"
      ],
      "files_created": [],
      "implementation_details": {
        "pipeline_integration": [
          "Replace current document processing with IngestionPipeline",
          "Integrate INGEST_CACHE with transformations",
          "Maintain existing API compatibility",
          "Add performance monitoring"
        ],
        "transformation_caching": [
          "SentenceSplitter caching",
          "Embedding generation caching",
          "Document parsing caching",
          "Metadata extraction caching"
        ]
      },
      "phase": 2,
      "pr_id": "PR-2.2",
      "priority": "high",
      "risk_level": "medium",
      "rollback_plan": "Restore original document processing without caching",
      "success_criteria": [
        "Document processing uses IngestionPipeline with caching",
        "90%+ cache hit rate for repeated operations",
        "No regression in processing accuracy",
        "Performance improvement measurable"
      ],
      "title": "Pipeline-Level Caching Integration",
      "verification_commands": [
        "pytest tests/unit/test_document_loader.py -v",
        "python -c \"import time; from src.utils.document import create_ingestion_pipeline; pipeline = create_ingestion_pipeline(); start = time.time(); print(f'Pipeline created in {time.time() - start:.2f}s')\""
      ]
    },
    {
      "blockers": [],
      "dependencies": [
        "PR-2.1"
      ],
      "description": "Implement semantic caching for LLM responses based on similarity",
      "estimated_effort_hours": 16,
      "files_changed": [
        "src/config/cache_config.py",
        "src/utils/core.py"
      ],
      "files_created": [],
      "implementation_details": {
        "cache_invalidation": "TTL-based with manual invalidation support",
        "semantic_caching_features": [
          "ChatMessage similarity comparison",
          "Configurable similarity threshold",
          "Cache key generation from message content",
          "Response caching and retrieval"
        ],
        "similarity_algorithm": "SHA256 hash of normalized message content"
      },
      "phase": 2,
      "pr_id": "PR-2.3",
      "priority": "medium",
      "risk_level": "high",
      "rollback_plan": "Disable semantic caching, use direct LLM calls",
      "success_criteria": [
        "Semantic cache correctly identifies similar messages",
        "Cache hit/miss rates are measurable",
        "Performance improvement for repeated similar queries",
        "Memory usage remains within acceptable bounds"
      ],
      "title": "Semantic Caching Implementation",
      "verification_commands": [
        "python -c \"from src.config.cache_config import SEMANTIC_CACHE; from llama_index.core.llms import ChatMessage; from llama_index.core.base.llms.types import ChatResponse; msg = [ChatMessage(content='Test message')]; response = ChatResponse(message=ChatMessage(content='Test response')); SEMANTIC_CACHE.set(msg, response); cached = SEMANTIC_CACHE.get(msg); print(f'Semantic cache working: {cached is not None}')\""
      ]
    },
    {
      "blockers": [],
      "dependencies": [
        "PR-1.4"
      ],
      "description": "Implement QueryPipeline with complexity analysis and routing",
      "estimated_effort_hours": 20,
      "files_changed": [],
      "files_created": [
        "src/agents/query_pipeline.py",
        "tests/unit/test_query_pipeline.py"
      ],
      "implementation_details": {
        "observability": [
          "Query processing time tracking",
          "Component execution logging",
          "Pipeline performance metrics"
        ],
        "pipeline_components": [
          "InputComponent for query ingestion",
          "ComplexityAnalyzer for routing decisions",
          "BaseRetriever integration",
          "ResponseSynthesizer integration"
        ],
        "routing_logic": {
          "complex": "word_count > 50, multiple questions, comparisons",
          "moderate": "word_count 20-50, basic complexity",
          "simple": "word_count < 20, single question"
        }
      },
      "phase": 3,
      "pr_id": "PR-3.1",
      "priority": "medium",
      "risk_level": "high",
      "rollback_plan": "Disable QueryPipeline, use standard query engines",
      "success_criteria": [
        "QueryPipeline creates and executes successfully",
        "Complexity analyzer correctly categorizes queries",
        "Routing logic directs queries appropriately",
        "Pipeline observability provides useful metrics"
      ],
      "title": "Basic QueryPipeline Implementation",
      "verification_commands": [
        "python -c \"from src.agents.query_pipeline import create_advanced_query_pipeline, ComplexityAnalyzer; analyzer = ComplexityAnalyzer(); result = analyzer.analyze_query('What is the main topic of this document?'); print(f'Query analysis: {result}')\"",
        "pytest tests/unit/test_query_pipeline.py -v"
      ]
    },
    {
      "blockers": [],
      "dependencies": [
        "PR-3.1"
      ],
      "description": "Integrate QueryPipeline with existing agent factory patterns",
      "estimated_effort_hours": 18,
      "files_changed": [
        "src/agents/agent_factory.py"
      ],
      "files_created": [],
      "implementation_details": {
        "agent_enhancement": [
          "Pipeline-aware tool selection",
          "Dynamic complexity routing",
          "Enhanced debugging capabilities",
          "Observability integration"
        ],
        "integration_strategy": [
          "Add QueryPipeline option to agent creation",
          "Maintain backward compatibility with ReAct agents",
          "Enable hybrid mode switching",
          "Performance comparison framework"
        ]
      },
      "phase": 3,
      "pr_id": "PR-3.2",
      "priority": "medium",
      "risk_level": "high",
      "rollback_plan": "Disable QueryPipeline integration, use standard ReAct agents",
      "success_criteria": [
        "Agents can use QueryPipeline for complex queries",
        "Backward compatibility with existing agents maintained",
        "Performance improvement measurable for complex queries",
        "Integration tests pass"
      ],
      "title": "Agent Integration with QueryPipeline",
      "verification_commands": [
        "pytest tests/unit/test_agent_factory.py -v",
        "python -c \"from src.agents.agent_factory import create_pipeline_agent; agent = create_pipeline_agent([], use_pipeline=True); print('Pipeline agent created successfully')\""
      ]
    }
  ],
  "implementation_checklist": {
    "during_migration": [
      {
        "owner": "development_team",
        "status": "pending",
        "task": "Execute PRs in sequence with full testing"
      },
      {
        "owner": "infrastructure_team",
        "status": "pending",
        "task": "Monitor performance metrics continuously"
      },
      {
        "owner": "development_team",
        "status": "pending",
        "task": "Document changes and update architectural decisions"
      }
    ],
    "post_migration": [
      {
        "owner": "development_team",
        "status": "pending",
        "task": "Validate all success criteria met"
      },
      {
        "owner": "development_team",
        "status": "pending",
        "task": "Update documentation and training materials"
      },
      {
        "owner": "project_manager",
        "status": "pending",
        "task": "Conduct retrospective and lessons learned session"
      }
    ],
    "pre_migration": [
      {
        "owner": "development_team",
        "status": "pending",
        "task": "Establish performance baseline"
      },
      {
        "owner": "infrastructure_team",
        "status": "pending",
        "task": "Set up development environment with Redis"
      },
      {
        "owner": "development_team",
        "status": "pending",
        "task": "Review and update test suite"
      },
      {
        "owner": "project_manager",
        "status": "pending",
        "task": "Create migration timeline and communication plan"
      }
    ]
  },
  "integration_plan": {
    "created_date": "2025-08-12",
    "plan_id": "llamaindex_ecosystem_integration",
    "summary": {
      "confidence": 85,
      "estimated_duration_days": "40-50",
      "priority": "high",
      "risk_level": "medium",
      "total_phases": 5,
      "total_prs": 16
    },
    "version": "1.0"
  },
  "phase_definitions": [
    {
      "dependencies": [],
      "description": "Replace custom Settings with LlamaIndex native Settings",
      "estimated_duration_days": 10,
      "name": "Global Settings Migration",
      "phase_id": 1,
      "pr_count": 4,
      "priority": "critical",
      "risk_level": "low",
      "success_metrics": {
        "code_reduction": "200+ lines eliminated",
        "configuration_consolidation": "100% LlamaIndex Settings usage",
        "performance_impact": "neutral or improved",
        "test_regression": "0 failing tests"
      }
    },
    {
      "dependencies": [
        "phase_1"
      ],
      "description": "Implement LlamaIndex IngestionCache and semantic caching",
      "estimated_duration_days": 12,
      "name": "Native Caching Integration",
      "phase_id": 2,
      "pr_count": 3,
      "priority": "high",
      "risk_level": "medium",
      "success_metrics": {
        "cache_hit_rate": "90%+ for repeated content",
        "infrastructure_reliability": "99% Redis uptime with graceful fallback",
        "memory_efficiency": "Controlled memory usage with TTL",
        "performance_improvement": "300-500% for repeated operations"
      }
    },
    {
      "dependencies": [
        "phase_1"
      ],
      "description": "Advanced query orchestration with routing and observability",
      "estimated_duration_days": 15,
      "name": "QueryPipeline Integration",
      "phase_id": 3,
      "pr_count": 2,
      "priority": "medium",
      "risk_level": "high",
      "success_metrics": {
        "observability_coverage": "Complete pipeline monitoring",
        "orchestration_capability": "Multi-step workflow support",
        "performance_optimization": "Improved handling of complex queries",
        "query_routing_accuracy": "95% correct complexity classification"
      }
    },
    {
      "dependencies": [
        "phase_3"
      ],
      "description": "Selective migration to LlamaIndex built-in agent patterns",
      "estimated_duration_days": 8,
      "name": "Agent Pattern Modernization",
      "phase_id": 4,
      "pr_count": 2,
      "priority": "medium",
      "risk_level": "medium",
      "success_metrics": {
        "code_simplification": "Reduced custom agent logic",
        "ecosystem_alignment": "Better LlamaIndex integration",
        "functionality_preservation": "100% existing capabilities maintained",
        "pattern_evaluation": "Complete assessment of current vs built-in patterns"
      }
    },
    {
      "dependencies": [
        "phase_1"
      ],
      "description": "Unified LLM provider configuration through Settings",
      "estimated_duration_days": 5,
      "name": "Provider Consolidation",
      "phase_id": 5,
      "pr_count": 1,
      "priority": "low",
      "risk_level": "low",
      "success_metrics": {
        "abstraction_quality": "Provider-agnostic application code",
        "code_reduction": "Eliminated provider-specific patterns",
        "configuration_unification": "Single provider switching interface",
        "switching_capability": "Runtime provider configuration changes"
      }
    }
  ],
  "risk_management": {
    "operational_risks": [
      {
        "contingency": "Immediate rollback to previous version",
        "impact": "high",
        "mitigation": "Atomic changes, feature flags, zero-downtime deployment",
        "probability": "low",
        "risk": "Migration downtime affects users"
      },
      {
        "contingency": "Rollback problematic changes",
        "impact": "medium",
        "mitigation": "Performance monitoring, gradual rollout, load testing",
        "probability": "medium",
        "risk": "Performance degradation during migration"
      }
    ],
    "technical_risks": [
      {
        "contingency": "Rollback to previous Settings implementation",
        "impact": "high",
        "mitigation": "Comprehensive testing, backward compatibility maintenance, gradual rollout",
        "probability": "medium",
        "risk": "Settings migration breaks existing functionality"
      },
      {
        "contingency": "Disable caching, use direct processing",
        "impact": "medium",
        "mitigation": "Graceful fallback to in-memory caching, Redis health monitoring",
        "probability": "low",
        "risk": "Cache infrastructure introduces dependencies"
      },
      {
        "contingency": "Revert to standard query engines",
        "impact": "medium",
        "mitigation": "Thorough documentation, comprehensive testing, observability tooling",
        "probability": "medium",
        "risk": "QueryPipeline increases system complexity"
      }
    ]
  },
  "success_criteria": {
    "qualitative_goals": {
      "developer_experience": "Simplified configuration and debugging",
      "extensibility": "Easier integration of new LlamaIndex features",
      "maintainability": "Reduced complexity through library-first patterns",
      "system_reliability": "Enhanced through native library optimizations"
    },
    "quantitative_targets": {
      "code_reduction": {
        "measurement": "Line count diff in configuration files",
        "target": "300+ lines eliminated",
        "timeline": "End of Phase 1"
      },
      "performance_improvement": {
        "measurement": "Execution time comparison for repeated operations",
        "target": "300-500% improvement in cached operations",
        "timeline": "End of Phase 2"
      },
      "test_coverage": {
        "measurement": "pytest-cov reports",
        "target": "Maintain >90% coverage",
        "timeline": "Throughout migration"
      },
      "zero_regressions": {
        "measurement": "End-to-end test results",
        "target": "All existing functionality preserved",
        "timeline": "Each PR merge"
      }
    }
  },
  "verification_framework": {
    "quality_gates": {
      "code_quality": [
        "ruff check passes with zero errors",
        "Type annotations coverage > 95%",
        "Docstring coverage > 90%",
        "Complexity metrics within acceptable bounds"
      ],
      "performance": [
        "No performance regressions detected",
        "Cache hit rates meet targets",
        "Memory usage within acceptable limits",
        "Response time improvements measurable"
      ],
      "reliability": [
        "Zero critical bugs introduced",
        "Graceful fallback mechanisms functional",
        "Error handling comprehensive",
        "Logging and monitoring adequate"
      ]
    },
    "testing_strategy": {
      "end_to_end_tests": {
        "scenarios": [
          "Complete document processing pipeline",
          "Multi-agent query resolution",
          "Cache invalidation and recovery",
          "Provider switching scenarios"
        ]
      },
      "integration_tests": {
        "scenarios": [
          "Settings propagation across components",
          "Cache performance under load",
          "QueryPipeline routing accuracy",
          "Agent integration functionality"
        ],
        "test_data_requirements": [
          "Sample documents of varying complexity",
          "Query sets for complexity analysis",
          "Performance benchmarking datasets"
        ]
      },
      "performance_tests": {
        "baseline_establishment": "Pre-migration performance metrics",
        "continuous_monitoring": "Performance tracking during migration",
        "regression_detection": "Automated performance regression alerts",
        "target_improvements": {
          "cache_performance": "300-500% improvement",
          "memory_usage": "Controlled growth with TTL management",
          "query_processing": "Maintained or improved latency"
        }
      },
      "unit_tests": {
        "coverage_target": 90,
        "frameworks": [
          "pytest",
          "pytest-asyncio",
          "pytest-cov"
        ],
        "new_tests_required": 25
      }
    }
  }
}
