# DocMind AI Configuration
# Copy this file to .env and update with your settings

# Multi-Agent Coordination Settings (REQ-0001 to REQ-0010)
DOCMIND_ENABLE_MULTI_AGENT=true
DOCMIND_AGENT_DECISION_TIMEOUT=300
DOCMIND_ENABLE_FALLBACK_RAG=true
DOCMIND_MAX_AGENT_RETRIES=2

# LLM Backend Configuration (REQ-0009: Local execution only)
DOCMIND_LLM_BACKEND=ollama
DOCMIND_MODEL_NAME=Qwen/Qwen3-4B-Instruct-2507-FP8
DOCMIND_LLM_BASE_URL=http://localhost:11434
# DOCMIND_LLM_API_KEY=optional_if_needed

# Context Management (REQ-0010)
DOCMIND_CONTEXT_WINDOW_SIZE=131072
DOCMIND_CONTEXT_BUFFER_SIZE=65536
DOCMIND_ENABLE_CONVERSATION_MEMORY=true

# Document Processing
DOCMIND_CHUNK_SIZE=512
DOCMIND_CHUNK_OVERLAP=50
DOCMIND_ENABLE_DOCUMENT_CACHING=true
DOCMIND_MAX_DOCUMENT_SIZE_MB=100

# Retrieval Configuration
DOCMIND_RETRIEVAL_STRATEGY=hybrid
DOCMIND_TOP_K=10
DOCMIND_USE_RERANKING=true
DOCMIND_RERANKER_TOP_K=5

# Embedding Configuration (REQ-0042, REQ-0043)
DOCMIND_EMBEDDING_MODEL=BAAI/bge-large-en-v1.5
DOCMIND_EMBEDDING_DIMENSION=1024
DOCMIND_USE_SPARSE_EMBEDDINGS=true

# Vector Database (REQ-0047)
DOCMIND_VECTOR_STORE_TYPE=qdrant
DOCMIND_QDRANT_URL=http://localhost:6333
DOCMIND_QDRANT_COLLECTION=docmind_docs

# DSPy Optimization (REQ-0091)
DOCMIND_ENABLE_DSPY_OPTIMIZATION=true
DOCMIND_DSPY_OPTIMIZATION_SAMPLES=20

# Performance Configuration
DOCMIND_MAX_QUERY_LATENCY_MS=2000
DOCMIND_MAX_MEMORY_GB=4.0
DOCMIND_MAX_VRAM_GB=14.0
DOCMIND_ENABLE_GPU_ACCELERATION=true
DOCMIND_QUANT_POLICY=fp8  # FP8 quantization

# vLLM FlashInfer Configuration (REQ: PyTorch 2.7.1 + CUDA 12.8)
VLLM_TORCH_BACKEND=cu128
VLLM_ATTENTION_BACKEND=FLASHINFER
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
TOKENIZERS_PARALLELISM=false

# vLLM Server Configuration for RTX 4090 16GB
VLLM_MODEL=Qwen/Qwen3-4B-Instruct-2507-FP8
VLLM_TENSOR_PARALLEL_SIZE=1
VLLM_GPU_MEMORY_UTILIZATION=0.85  # 13.6GB of 16GB
VLLM_MAX_MODEL_LEN=131072  # 128K context for Qwen3
VLLM_ENABLE_PREFIX_CACHING=true
VLLM_USE_V2_BLOCK_MANAGER=true
VLLM_KV_CACHE_DTYPE=fp8_e5m2  # FP8 KV cache optimization
VLLM_QUANTIZATION=fp8  # Enable FP8 quantization
VLLM_MAX_NUM_BATCHED_TOKENS=8192  # Optimize for throughput
VLLM_MAX_NUM_SEQS=256  # Concurrent sequences

# CUDA Environment Variables
CUDA_VISIBLE_DEVICES=0
NVIDIA_VISIBLE_DEVICES=all
CUDA_HOME=/usr/local/cuda

# Persistence
DOCMIND_DATA_DIR=./data
DOCMIND_CACHE_DIR=./cache
DOCMIND_SQLITE_DB_PATH=./data/docmind.db
DOCMIND_ENABLE_WAL_MODE=true

# Logging
DOCMIND_LOG_LEVEL=INFO
DOCMIND_LOG_FILE=./logs/docmind.log
DOCMIND_ENABLE_PERFORMANCE_LOGGING=true

# UI Configuration
DOCMIND_STREAMLIT_PORT=8501
DOCMIND_ENABLE_UI_DARK_MODE=true

# Advanced Features
DOCMIND_ENABLE_GRAPHRAG=false
DOCMIND_ENABLE_MULTIMODAL=false
DOCMIND_ANALYSIS_MODES=["detailed","summary","comparison"]